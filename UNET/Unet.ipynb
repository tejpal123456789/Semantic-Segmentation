{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of the UNET Architecture from the paper \n",
        "\n",
        "https://arxiv.org/pdf/1505.04597.pdf"
      ],
      "metadata": {
        "id": "nGHP3Gv6LGAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n"
      ],
      "metadata": {
        "id": "JjEjlIc6LTX5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class doubleconvlayer(nn.Module):\n",
        "\n",
        "  def __init__(self,input_channels,output_channels):                                  # input image has size of 3x512x512\n",
        "    super(doubleconvlayer,self).__init__()  \n",
        "\n",
        "    self.input_channels=input_channels\n",
        "    self.output_channels=output_channels\n",
        "\n",
        "    self.conv=nn.Sequential(\n",
        "        nn.Conv2d(in_channels  =input_channels,out_channels=output_channels,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(output_channels),\n",
        "        nn.ReLU(),                             # output --> (n-f+1)/s --> 512-3+1=510 ---> Nx64x510x510\n",
        "        nn.Conv2d(in_channels=output_channels,out_channels=output_channels,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(output_channels),\n",
        "        nn.ReLU()                              # output --> (n-f+1)/s --> 510-3+1=508 ---> Nx64x508x508\n",
        "    ) \n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.conv(x)\n",
        "\n",
        "\n",
        "# returns batch_sizex64x508x508\n",
        "m=doubleconvlayer(3,64)\n",
        "x=torch.randn(5,3,512,512)\n",
        "y=m(x)\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyazghFsLiJC",
        "outputId": "1e59e617-5e7d-48e9-8bcd-a25e4fc12fd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 512, 512])\n",
            "torch.Size([5, 64, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class UNET(nn.Module):\n",
        "  def __init__(self,input_channels=3,output_channels=1,features=[64,128,256,512]):\n",
        "    super(UNET,self).__init__()\n",
        "\n",
        "    self.ups=nn.ModuleList()\n",
        "    self.downs=nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "    # downs\n",
        "\n",
        "    for feature in features:\n",
        "\n",
        "      self.downs.append(doubleconvlayer(input_channels,feature))       # i have added each double conv in as a element of list\n",
        "                                                                     # modulelist() can be used to perform operation in this case\n",
        "      input_channels=feature\n",
        "\n",
        "   # print(self.downs)\n",
        "\n",
        "\n",
        "   # uppart of the UNET , skip for a second for the bottleneck\n",
        "\n",
        "    for feature in reversed(features):\n",
        "\n",
        "      self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2,))\n",
        "\n",
        "      self.ups.append(doubleconvlayer(feature*2,feature))\n",
        "\n",
        "\n",
        "    self.bottleneck=doubleconvlayer(features[-1],features[-1]*2)\n",
        "\n",
        "    self.final_layer= nn.Conv2d(features[0], output_channels, kernel_size=1)   \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    skip_connections=[]\n",
        "\n",
        "    for down in self.downs:                          # 1st --> n+2p-f+1/s --> Nx 64*512*512 --> pool , N*64*256*256\n",
        "\n",
        "      x=down(x)\n",
        "      skip_connections.append(x)\n",
        "      x=self.pool(x)\n",
        "     # print(x.shape)\n",
        "\n",
        "    x=self.bottleneck(x)\n",
        "    skip_connections=skip_connections[::-1]\n",
        "\n",
        "    \n",
        "    for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "    return self.final_layer(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "m=UNET()\n",
        "x=torch.randn(5,3,512,512)\n",
        "y=m(x)\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJNEgfXvOdat",
        "outputId": "d21f6606-e2f8-4d5e-ba1b-1b2c04152b9c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 512, 512])\n",
            "torch.Size([5, 1, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "GBpicSkns7fD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8IWaXOP7SYFg"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}