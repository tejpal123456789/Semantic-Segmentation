{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "hPm35E8rREZc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Z822ywdARXHh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from albumentations import HorizontalFlip,VerticalFlip,ElasticTransform,GridDistortion,OpticalDistortion\n",
        "\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAoNIEadeM-b",
        "outputId": "4a3e774c-64d1-4f37-c2b6-046a5d31692b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1476 1476 72 72\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\" X = Images and Y = masks \"\"\"\n",
        "\n",
        "    train_x = sorted(glob(os.path.join(path, \"train\", \"train\", \"*.jpg\")))\n",
        "    train_y = sorted(glob(os.path.join(path, \"train_masks\", \"train_masks\", \"*.gif\")))\n",
        "\n",
        "    test_x = sorted(glob(os.path.join(path, \"validation_car\", \"*.jpg\")))\n",
        "    test_y = sorted(glob(os.path.join(path, \"validation_mask\", \"*.gif\")))\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "\n",
        "(train_x, train_y), (test_x, test_y)=load_data('/content/drive/MyDrive/Segmentation/car_unet')\n",
        "\n",
        "print(len(train_x),len(train_y),len(test_x),len(test_y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "ce0Gx4NTe3aU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def create_dir(path):\n",
        "#     if not os.path.exists(path):\n",
        "#         os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "fuEAuQhaflKH"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "def augment_data(images, masks, save_path, augment=True):\n",
        "    H = 512\n",
        "    W = 512\n",
        "\n",
        "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
        "        # \"\"\" Extracting names \"\"\"\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        # \"\"\" Reading image and mask \"\"\"\n",
        "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "       # y = cv2.imread(y,cv2.IMREAD_COLOR)\n",
        "        y = imageio.mimread(y)[0]\n",
        "\n",
        "        # if augment == True:\n",
        "        #     aug = HorizontalFlip(p=1.0)\n",
        "        #     augmented = aug(image=x, mask=y)\n",
        "        #     x1 = augmented[\"image\"]\n",
        "        #     y1 = augmented[\"mask\"]\n",
        "\n",
        "        #     aug = VerticalFlip(p=1.0)\n",
        "        #     augmented = aug(image=x, mask=y)\n",
        "        #     x2 = augmented[\"image\"]\n",
        "        #     y2 = augmented[\"mask\"]\n",
        "\n",
        "        #     aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
        "        #     augmented = aug(image=x, mask=y)\n",
        "        #     x3 = augmented['image']\n",
        "        #     y3 = augmented['mask']\n",
        "\n",
        "        #     aug = GridDistortion(p=1)\n",
        "        #     augmented = aug(image=x, mask=y)\n",
        "        #     x4 = augmented['image']\n",
        "        #     y4 = augmented['mask']\n",
        "\n",
        "        #     aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
        "        #     augmented = aug(image=x, mask=y)\n",
        "        #     x5 = augmented['image']\n",
        "        #     y5 = augmented['mask']\n",
        "\n",
        "        #     X = [x1, x2, x3, x4, x5]\n",
        "        #     Y = [y1, y2, y3, y4, y5]\n",
        "\n",
        "        # else:\n",
        "\n",
        "        X = [x]    \n",
        "        Y = [y]\n",
        "\n",
        "        index = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H))\n",
        "            m = cv2.resize(m, (W, H))\n",
        "\n",
        "            if len(X) == 1:\n",
        "                tmp_image_name = f\"{name}.jpg\"\n",
        "                tmp_mask_name = f\"{name}.jpg\"\n",
        "            else:\n",
        "                tmp_image_name = f\"{name}_{index}.jpg\"\n",
        "                tmp_mask_name = f\"{name}_{index}.jpg\"\n",
        "\n",
        "            image_path = os.path.join(save_path, \"validation_car\", tmp_image_name)\n",
        "            mask_path = os.path.join(save_path, \"validation_mask\", tmp_mask_name)\n",
        "\n",
        "            cv2.imwrite(image_path, i)\n",
        "            cv2.imwrite(mask_path, m)\n",
        "\n",
        "            index += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "Jk9nXw_BgY2A"
      },
      "outputs": [],
      "source": [
        "\n",
        "#augment_data(train_x, train_y, \"/content/drive/MyDrive/Segmentation/car_unet/\", augment=True)\n",
        "#augment_data(test_x, test_y, \"/content/drive/MyDrive/Segmentation/retina_unet/new_data/test/\", augment=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#augment_data(test_x, test_y, \"/content/drive/MyDrive/Segmentation/car_unet/\", augment=True)"
      ],
      "metadata": {
        "id": "Ac8Bse3qhr4e"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "Ht6cw_7fmScA"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(\n",
        "            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
        "    ):\n",
        "        super(UNET, self).__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of UNET\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of UNET\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(\n",
        "                    feature*2, feature, kernel_size=2, stride=2,\n",
        "                )\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "    \n",
        "        print(len(self.downs))\n",
        "        print(len(self.ups))\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "IPwaE6CtmpRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a0effd-f7ca-46d4-ce3b-30e8fbdb2438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "model=UNET()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating class dataset"
      ],
      "metadata": {
        "id": "MQS1B7M1hovY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "class retina_dataset(Dataset):\n",
        "\n",
        "  def __init__(self,images_path,masks_path):\n",
        "     \n",
        "   # images=os.listdir(image_path)\n",
        "    self.images_path=images_path\n",
        "    self.masks_path=masks_path\n",
        "    self.n_samples=len(images_path)\n",
        "\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "        \"\"\" Reading image \"\"\"\n",
        "        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n",
        "        image = image/255.0 ## (512, 512, 3)\n",
        "        image = np.transpose(image, (2, 0, 1))  ## (3, 512, 512)\n",
        "        image = image.astype(np.float32)\n",
        "        image = torch.from_numpy(image)\n",
        "\n",
        "        \"\"\" Reading mask \"\"\"\n",
        "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
        "        mask = mask/255.0   ## (512, 512)\n",
        "        mask = np.expand_dims(mask, axis=0) ## (1, 512, 512)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask = torch.from_numpy(mask)\n",
        "\n",
        "        return image,mask\n",
        "  def __len__(self):\n",
        "    return self.n_samples     \n",
        "\n"
      ],
      "metadata": {
        "id": "zqGDggoB1V-C"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# losses"
      ],
      "metadata": {
        "id": "n-3fl-6Ti8wK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        return 1 - dice\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "\n",
        "        return Dice_BCE\n"
      ],
      "metadata": {
        "id": "FT-mj7uki-Fn"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training "
      ],
      "metadata": {
        "id": "TOKI8DEBjPTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Load dataset \"\"\"\n",
        "train_x = sorted(glob(\"/content/drive/MyDrive/Segmentation/retina_unet/new_data/train/image/*\"))\n",
        "train_y = sorted(glob(\"/content/drive/MyDrive/Segmentation/retina_unet/new_data/train/mask/*\"))\n",
        "\n",
        "\n",
        "test_x = sorted(glob(\"/content/drive/MyDrive/Segmentation/retina_unet/new_data/test/image/*\"))\n",
        "test_y = sorted(glob(\"/content/drive/MyDrive/Segmentation/retina_unet/new_data/test/mask/*\"))\n",
        "\n",
        "data_str = f\"Dataset Size:\\nTrain: {len(train_x)} - Valid: {len(test_x)}\\n\"\n",
        "print(data_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYVGY1RDjOr8",
        "outputId": "a6b80dc1-091c-48d1-a640-9cd95a73abfb"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size:\n",
            "Train: 120 - Valid: 20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nubJKd_Rj2FD"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\" Dataset and loader \"\"\"\n",
        "train_dataset = retina_dataset(train_x, train_y)\n",
        "valid_dataset = retina_dataset(test_x, test_y)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "batch_size=2\n",
        "train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "        dataset=valid_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n"
      ],
      "metadata": {
        "id": "CR4jB0WI0NJm"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')   ## GTX 1060 6GB\n",
        "model = UNET()\n",
        "model = model.to(device)\n",
        "lr=1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
        "loss_fn = DiceBCELoss()\n",
        "\n",
        "print(device)\n"
      ],
      "metadata": {
        "id": "4zELNc51Kfpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128ba11c-8fd8-49de-feb3-c01ec07f18b9"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "8\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vZP5CcNr0rOx"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training part of the UNET architecture"
      ],
      "metadata": {
        "id": "-j0AWhuzs3c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    loop=tqdm(loader)\n",
        "    for x, y in loop:\n",
        "        x = x.to(device, dtype=torch.float32)\n",
        "        y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss\n",
        "\n",
        "def evaluate(model, loader, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "    loop=tqdm(loader)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loop:\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss    "
      ],
      "metadata": {
        "id": "g5dWvuhDs3I7"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs=50\n",
        "\n",
        "# \"\"\" Calculate the time taken \"\"\"\n",
        "# def epoch_time(start_time, end_time):\n",
        "#     elapsed_time = end_time - start_time\n",
        "#     elapsed_mins = int(elapsed_time / 60)\n",
        "#     elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "#     return elapsed_mins, elapsed_secs\n",
        "# checkpoint_path='/content/drive/MyDrive/Segmentation/retina_unet/checkpoint.pth'\n",
        "# best_valid_loss = float(\"inf\")\n",
        "# import time\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#         start_time = time.time()\n",
        "\n",
        "#         train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
        "#         valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
        "#         \"\"\" Saving the model \"\"\"\n",
        "#         if valid_loss < best_valid_loss:\n",
        "#             data_str = f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}\"\n",
        "#             print(data_str)\n",
        "\n",
        "#             best_valid_loss = valid_loss\n",
        "#             torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "#         end_time = time.time()\n",
        "#         epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "#         data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
        "#         data_str += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
        "#         data_str += f'\\t Val. Loss: {valid_loss:.3f}\\n'\n",
        "#         print(data_str)"
      ],
      "metadata": {
        "id": "9QbOdFjv0ss7"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the UNET"
      ],
      "metadata": {
        "id": "mAe4kWNZ3bUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test x and test y are there for the test purpose \n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "from operator import add\n"
      ],
      "metadata": {
        "id": "fd9RFzKouo0j"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model weights with which we will test\n",
        "\n",
        "import time\n",
        "def calculate_metric(y_true,y_pred):\n",
        "  # ground truth\n",
        "  y_true=y_true.cpu().numpy()\n",
        "  y_true=y_true>0.5\n",
        "  y_true = y_true.astype(np.uint8)\n",
        "  y_true = y_true.reshape(-1)\n",
        "\n",
        "  # prediction\n",
        "\n",
        "  y_pred=y_pred.cpu().numpy()\n",
        "  y_pred=y_pred>0.5\n",
        "  y_pred=y_pred.astype(np.int8)\n",
        "  y_pred=y_pred.reshape(-1)\n",
        "  \n",
        "  # calculations of \n",
        "  score_jaccard = jaccard_score(y_true, y_pred)\n",
        "  score_f1 = f1_score(y_true, y_pred)\n",
        "  score_recall = recall_score(y_true, y_pred)\n",
        "  score_precision = precision_score(y_true, y_pred)\n",
        "  score_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "  return [score_jaccard, score_f1, score_recall, score_precision, score_acc]\n",
        "\n",
        "\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n",
        "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n",
        "    return mask\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Segmentation/retina_unet/checkpoint.pth\"\n",
        "\n",
        "\"\"\" Load the checkpoint \"\"\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNET()\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "#model.eval()    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7os7MIFRt3-7",
        "outputId": "10daab2d-1ba4-4bc1-8b6b-264302b7d258"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xrZw5YmJAsKz"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "time_taken = []\n",
        "import tqdm\n",
        "for i, (x, y) in (enumerate(zip(test_x, test_y))):\n",
        "        \"\"\" Extract the name \"\"\"\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \"\"\" Reading image \"\"\"\n",
        "        image = cv2.imread(x, cv2.IMREAD_COLOR) ## (512, 512, 3)\n",
        "        ## image = cv2.resize(image, size)\n",
        "        x = np.transpose(image, (2, 0, 1))      ## (3, 512, 512)\n",
        "        x = x/255.0\n",
        "        x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
        "        x = x.astype(np.float32)\n",
        "        x = torch.from_numpy(x)\n",
        "        x = x.to(device)\n",
        "\n",
        "        \"\"\" Reading mask \"\"\"\n",
        "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "        ## mask = cv2.resize(mask, size)\n",
        "        y = np.expand_dims(mask, axis=0)            ## (1, 512, 512)\n",
        "        y = y/255.0\n",
        "        y = np.expand_dims(y, axis=0)               ## (1, 1, 512, 512)\n",
        "        y = y.astype(np.float32)\n",
        "        y = torch.from_numpy(y)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            \"\"\" Prediction and Calculating FPS \"\"\"\n",
        "            start_time = time.time()\n",
        "            pred_y = model(x)\n",
        "            pred_y = torch.sigmoid(pred_y)\n",
        "            total_time = time.time() - start_time\n",
        "            time_taken.append(total_time)\n",
        "\n",
        "\n",
        "            score = calculate_metric(y, pred_y)\n",
        "            metrics_score = list(map(add, metrics_score, score))\n",
        "            pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n",
        "            pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
        "            pred_y = pred_y > 0.5\n",
        "            pred_y = np.array(pred_y, dtype=np.uint8)\n",
        "\n",
        "        \"\"\" Saving masks \"\"\"\n",
        "        ori_mask = mask_parse(mask)\n",
        "        pred_y = mask_parse(pred_y)\n",
        "        line = np.ones((512, 10, 3)) * 128\n",
        "\n",
        "        cat_images = np.concatenate(\n",
        "            [image, line, ori_mask, line, pred_y * 255], axis=1\n",
        "        )\n",
        "        cv2.imwrite(f\"/content/drive/MyDrive/Segmentation/retina_unet/results/{name}.png\", cat_images)\n",
        "\n",
        "jaccard = metrics_score[0]/len(test_x)\n",
        "f1 = metrics_score[1]/len(test_x)\n",
        "recall = metrics_score[2]/len(test_x)\n",
        "precision = metrics_score[3]/len(test_x)\n",
        "acc = metrics_score[4]/len(test_x)\n",
        "print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f}\")\n",
        "\n",
        "fps = 1/np.mean(time_taken)\n",
        "print(\"FPS: \", fps)\n",
        "\n"
      ],
      "metadata": {
        "id": "N_sUOr3AA499",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d23162-209a-4f6e-8be6-f24ae9ba31dd"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard: 0.6674 - F1: 0.8003 - Recall: 0.7918 - Precision: 0.8144 - Acc: 0.9657\n",
            "FPS:  192.96355167059636\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "retina_unet.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}